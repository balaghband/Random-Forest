{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hT5pj1pcdr5"
      },
      "source": [
        "Import Packages<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EP2P6YkrcPYz",
        "tags": [
          "Keep"
        ]
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import chi2\n",
        "from scipy.stats import mode\n",
        "import math\n",
        "#print (\"Leo_test\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tCx7V6cyczHk"
      },
      "source": [
        "Parameter setting\n",
        "1. Folder path\n",
        "2. Target field name\n",
        "3. Target values\n",
        "4. Index filed name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sgigpv38cyjp",
        "tags": [
          "Keep"
        ]
      },
      "outputs": [],
      "source": [
        "root_folder = 'HM1/'\n",
        "train_file = 'train.csv'\n",
        "#train_file = 'iris.csv'\n",
        "test_file = 'test.csv'\n",
        "Index = 'TransactionID'\n",
        "Date = 'TransactionDT'\n",
        "#Index = ''\n",
        "Target = 'isFraud'\n",
        "#Target = 'species'\n",
        "#Target_value = 'versicolor' # 1\n",
        "Target_value = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6RTS01vc75z"
      },
      "source": [
        "Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjh3NNbNcdFq",
        "outputId": "587d29e5-05ce-4d34-fd95-3cc5fe52c6ad",
        "tags": [
          "Keep"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(472432, 27)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv(root_folder + train_file)\n",
        "#test = pd.read_csv(root_folder + test_file)\n",
        "#print (train.columns)\n",
        "train.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lxkWYjVUhiwr"
      },
      "source": [
        "Basic statistics <br>\n",
        "How much missing values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ws03VS0Qhkmw",
        "outputId": "0f1a7996-737a-4719-d537-94301f972e99",
        "tags": [
          "Keep"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['C1' 'C10' 'C11' 'C12' 'C13' 'C14' 'C2' 'C3' 'C4' 'C5' 'C6' 'C7' 'C8'\n",
            " 'C9' 'TransactionAmt' 'isFraud']\n",
            "['ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'Num_Cat']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ProductCD</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>card1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>card2</th>\n",
              "      <td>7203.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>card3</th>\n",
              "      <td>1258.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>card4</th>\n",
              "      <td>1269.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>card5</th>\n",
              "      <td>3404.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>card6</th>\n",
              "      <td>1261.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>addr1</th>\n",
              "      <td>52428.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>addr2</th>\n",
              "      <td>52428.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransactionAmt</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C5</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C6</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C8</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C9</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C10</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C11</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C12</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C13</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C14</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isFraud</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0\n",
              "ProductCD           0.0\n",
              "card1               0.0\n",
              "card2            7203.0\n",
              "card3            1258.0\n",
              "card4            1269.0\n",
              "card5            3404.0\n",
              "card6            1261.0\n",
              "addr1           52428.0\n",
              "addr2           52428.0\n",
              "TransactionAmt      0.0\n",
              "C1                  0.0\n",
              "C2                  0.0\n",
              "C3                  0.0\n",
              "C4                  0.0\n",
              "C5                  0.0\n",
              "C6                  0.0\n",
              "C7                  0.0\n",
              "C8                  0.0\n",
              "C9                  0.0\n",
              "C10                 0.0\n",
              "C11                 0.0\n",
              "C12                 0.0\n",
              "C13                 0.0\n",
              "C14                 0.0\n",
              "isFraud             0.0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "size = train.shape\n",
        "Columns = train.columns.values\n",
        "Columns = Columns[Columns != Index]\n",
        "Columns = Columns[Columns != Date]\n",
        "Categoric_features = ['ProductCD','card1','card2','card3','card4','card5','card6','addr1','addr2']\n",
        "#Categoric_features = []\n",
        "Numeric_features = np.setdiff1d(Columns, Categoric_features)\n",
        "MissingData = pd.DataFrame(index = Columns)\n",
        "for i in Columns:\n",
        "  #fig, ax  = plt.subplots(figsize= (5,3))\n",
        "  #plt.hist(train[i])\n",
        "  # if i in Numeric_features:\n",
        "  #       identify = 'Numeric'\n",
        "  # else:\n",
        "  #   identify = 'Categoric'\n",
        "  # plt.title(f\"{i:}, {identify}\")\n",
        "  # if i == 'isFraud':\n",
        "  #       continue\n",
        "  tmp_df = train[(train[i]=='NotFound') | (train[i].isna())] #test[(test[i]=='NotFound') | (test[i].isna())]\n",
        "  MissingData.loc[i,0] = tmp_df.shape[0]\n",
        "Categoric_features.append('Num_Cat')\n",
        "print (Numeric_features)\n",
        "print (Categoric_features)\n",
        "MissingData"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dealing with missing data in <font color = 'red'> <b>train phase </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [
          "Keep"
        ]
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00, 11.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.871657720052833  of data left in train_filter\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "############# 1. remove missing records ############\n",
        "train_filter = train.copy() \n",
        "############# 1. remove missing records ############\n",
        "\n",
        "\n",
        "############# 2. Use most frequency values ############\n",
        "train_Impu = train.copy() \n",
        "#test_Impu = test.copy()\n",
        "############# 2. Use most frequency values ############\n",
        "\n",
        "for i in tqdm(Columns):\n",
        "  train_filter = train_filter[train_filter[i]!='NotFound']\n",
        "  train_Impu.loc[train_Impu[i]=='NotFound',i] = train_Impu[i].value_counts().idxmax()\n",
        "  # if i != 'isFraud':\n",
        "  #   test_Impu[test_Impu[i]=='NotFound'] = test[i].value_counts().idxmax()\n",
        "print (train_filter.shape[0]/size[0],\" of data left in train_filter\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b7emVzAam8az"
      },
      "source": [
        "<b>Information gain function<br></b>\n",
        "| Input Variable | Type | Definition |\n",
        "| --- | --- | --- |\n",
        "| <font color = 'green'> Input_Dataframe</font> | pandas.DataFrame | This is your choosen subset of training data |\n",
        "| <font color = 'green'> Split_feature </font>| String | The choose feature for calculating Information gain |\n",
        "| <font color = 'green'> IG_methods</font> | String | 3 options, <font color = 'red'>Gini </font>: Gini index, <font color = 'red'>Entropy </font>: Max Entropy, <font color = 'red'>MisEr </font>: Miss classification|\n",
        "| <font color = 'green'> Num_Cat </font>| String | 2 options, <font color = 'red'> Num </font>: Split feature is a numeric feature, <font color = 'red'> Cat </font>: Split feature is a categorical feature |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This function has 2 possible returns: <br>\n",
        "&emsp;-- <font color = 'red'>[IG_feature, Split point]</font>: if <font color = 'green'>Split_feature</font> is a <b>numeric</b> feature<br>\n",
        "&emsp;&emsp;-- <b>IG_feature</b>: single float variable representing <b>Information Gain</b> of <font color = 'green'>Split_feature</font>,<br> \n",
        "&emsp;&emsp;-- <b>Split point </b>: single float variable, the best binary split point for this numberic feature <font color = 'green'>Split_feature</font>,<br> \n",
        "&emsp;-- <font color = 'red'>[IG_feature, -3.14]</font>: if <font color = 'green'>Split_feature</font> is a<b> categorical </b>feature<br>\n",
        "&emsp;&emsp;-- <b>IG_feature </b>: same as previous<br>\n",
        "&emsp;&emsp;-- <b>-3.14 </b>: Meaningless, and not be used in the future. Just to make this function work recursively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hk1XEsC-m-Nx",
        "tags": [
          "Keep"
        ]
      },
      "outputs": [],
      "source": [
        "def Info_Gain(Input_Dataframe, Split_feature, IG_methods, Num_Cat): #IG_methods = 'Gini'/ 'Entropy' / 'MisEr'\n",
        "\n",
        "  length = len(Input_Dataframe)\n",
        "  Fraud_arr = Input_Dataframe[Target]\n",
        "\n",
        "  # propability of Fraud and not Fraud\n",
        "  P_isF = np.sum(Fraud_arr == Target_value)/length\n",
        "  P_notF = 1-P_isF\n",
        "\n",
        "  Impu_root = 0\n",
        "  Impu_leaves = [] #Impurity of each leaves\n",
        "  Prop_leaves = [] #Propotion of each leaves\n",
        "  IG_feature_Num = [] #IGs for numeric features\n",
        "\n",
        "  ######### if Num_Cat == 'Mid' #########\n",
        "  # This is used for recursive. \n",
        "  # When the Split_feature is a numeric feature, Info_Gain function will convert the numeric feature into a binary categorical feature (Line 74)\n",
        "  # And then re-call the function Info_Gain(Input_Dataframe, Split_feature, IG_methods, 'Mid') , so the function will calculate the information gain for the numeric feature with the specific binary seperation\n",
        "  ######### if Num_Cat == 'Mid' #########\n",
        "  if Num_Cat == 'Cat' or Num_Cat == 'Mid':\n",
        "    # Feature_classes: all unique classes, e.g. ['C','W','R', ...] for 'ProductCD'\n",
        "    # P_unique_Fea: count for each classes, e.g. [100, 200, 100, ...]\n",
        "    Feature_classes, P_unique_Fea = np.unique(Input_Dataframe[Split_feature], return_counts = True)\n",
        "\n",
        "    if IG_methods == 'Gini':\n",
        "      Impu_root = 1 - P_isF ** 2  - P_notF ** 2\n",
        "      for i in Feature_classes:\n",
        "        Sub_df = Input_Dataframe[Input_Dataframe[Split_feature] == i]\n",
        "        Sub_len = len(Sub_df)\n",
        "        Sub_P_isF = np.sum(Sub_df[Target] == Target_value)/Sub_len\n",
        "        Sub_P_notF = 1-Sub_P_isF\n",
        "        Impu_leaves.append(1 - Sub_P_isF ** 2  - Sub_P_notF ** 2)\n",
        "        Prop_leaves.append(Sub_len/length)\n",
        "    elif IG_methods == 'MisEr':\n",
        "      Impu_root = 1 - max(P_isF,P_notF)\n",
        "      for i in Feature_classes:\n",
        "        Sub_df = Input_Dataframe[Input_Dataframe[Split_feature] == i]\n",
        "        Sub_len = len(Sub_df)\n",
        "        Sub_P_isF = np.sum(Sub_df[Target] == Target_value)/Sub_len\n",
        "        Sub_P_notF = 1-Sub_P_isF\n",
        "        Impu_leaves.append(1 - max(Sub_P_isF,Sub_P_notF))\n",
        "        Prop_leaves.append(Sub_len/length)\n",
        "\n",
        "    elif IG_methods == 'Entropy':\n",
        "          \n",
        "      ########## to deal with log(0) with 0 occurance ###########\n",
        "      if P_isF == 0:\n",
        "        Ent_P_isF = 0\n",
        "      else:\n",
        "        Ent_P_isF = P_isF * np.log2(P_isF)\n",
        "      if P_notF == 0:\n",
        "        Ent_P_notF = 0\n",
        "      else:\n",
        "        Ent_P_notF = P_notF * np.log2(P_notF)\n",
        "      ########## to deal with log(0) with 0 occurance ###########\n",
        "\n",
        "      Impu_root = -(Ent_P_notF + Ent_P_isF)\n",
        "      for i in Feature_classes:\n",
        "        Sub_df = Input_Dataframe[Input_Dataframe[Split_feature] == i]\n",
        "        Sub_len = len(Sub_df)\n",
        "        Sub_P_isF = np.sum(Sub_df[Target] == Target_value)/Sub_len\n",
        "        Sub_P_notF = 1-Sub_P_isF\n",
        "        if Sub_P_isF == 0:\n",
        "          Ent_Sub_P_isF = 0\n",
        "        else:\n",
        "          Ent_Sub_P_isF = Sub_P_isF * np.log2(Sub_P_isF)\n",
        "        if Sub_P_notF == 0:\n",
        "          Ent_Sub_P_not_F = 0\n",
        "        else:\n",
        "          Ent_Sub_P_not_F = Sub_P_notF * np.log2(Sub_P_notF)\n",
        "        Impu_leaves.append(-(Ent_Sub_P_isF + Ent_Sub_P_not_F))\n",
        "        Prop_leaves.append(Sub_len/length)\n",
        "    \n",
        "  elif Num_Cat == 'Num':\n",
        "    # this will automatically sort those unique values\n",
        "    Sort_Input = np.unique(Input_Dataframe[Split_feature])\n",
        "    Sort_Input = Sort_Input.astype(np.float32)\n",
        "\n",
        "    # try every numeric values, add those information gain into the list \"IG_feature_Num\"   \n",
        "    for i in Sort_Input:\n",
        "      tmp_Input_Dataframe = Input_Dataframe.copy()\n",
        "      # binary seperate the feature\n",
        "      tmp_Input_Dataframe.loc[tmp_Input_Dataframe[Split_feature] <= i,Split_feature] = 0\n",
        "      tmp_Input_Dataframe.loc[tmp_Input_Dataframe[Split_feature] > i,Split_feature] = 1\n",
        "      IG_feature_Num.append(Info_Gain(tmp_Input_Dataframe,Split_feature, IG_methods, 'Mid'))\n",
        "\n",
        "  Impu_root = np.array(Impu_root)\n",
        "  Prop_leaves = np.array(Prop_leaves)\n",
        "\n",
        "  # calculate the gain ratio if there are too much classes, this could reduce the breadth of the tree \n",
        "  if (Split_feature in Categoric_features) and (len(Feature_classes) > 200):\n",
        "    P_unique_Fea = P_unique_Fea/sum(P_unique_Fea)\n",
        "    log_P = np.log2(P_unique_Fea)\n",
        "    SplitInfo = -np.matmul(P_unique_Fea,log_P.T)\n",
        "    IG_feature =  float(f\"{Impu_root - np.matmul(Impu_leaves,Prop_leaves.T):.5f}\")\n",
        "    IG_feature = IG_feature/SplitInfo\n",
        "  # simplyt using the information gain\n",
        "  elif (Split_feature in Categoric_features) or (Num_Cat == 'Mid'):\n",
        "    IG_feature =  float(f\"{Impu_root - np.matmul(Impu_leaves,Prop_leaves.T):.5f}\")\n",
        "\n",
        "  \n",
        "  if Num_Cat == 'Num':\n",
        "    IG_feature = max(IG_feature_Num)\n",
        "    return [IG_feature, Sort_Input[IG_feature_Num.index(IG_feature)]] \n",
        "  elif Num_Cat == 'Mid':\n",
        "    return IG_feature\n",
        "  elif Num_Cat == 'Cat':\n",
        "    return [IG_feature, -3.1415926] # -pi means it is a categorical feature\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.00028, 0.0]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# demo of Info_Gain function\n",
        "Info_Gain(train[0:4000], IG_methods= 'Gini', Split_feature='card1',Num_Cat='Cat')\n",
        "Info_Gain(train[0:4000], IG_methods='Gini', Num_Cat='Num', Split_feature='C1')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Chi-square test function<br></b>\n",
        "| Input Variable | Type | Definition |\n",
        "| --- | --- | --- |\n",
        "| <font color = 'green'> Input_Dataframe</font> | pandas.DataFrame | This is your choosen subset of training data |\n",
        "| <font color = 'green'> Split_feature </font>| String | The choose feature for calculating Chi_Square |\n",
        "| <font color = 'green'> *Split_pts_Num</font> | float | This is an optional variable, it's only used in the function itself recursively|\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This function has 2 possible returns: <br>\n",
        "&emsp;-- <font color = 'red'>0</font>: The selected feature fails the Chi-test <br>\n",
        "&emsp;-- <font color = 'red'>1</font>: The selected feature passes the Chi-test\n",
        "\n",
        "To make sure that the tree can grow properly (increase possibility of growing to at least 2-depth) for small subset of the data (used for debuging the algorithm), user can set manually <font color = red>Chi-baisc = Chi-basic - 5</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Chi_test(Input_Dataframe, Split_feature, *Split_pts_Num):\n",
        "  length = Input_Dataframe.shape[0]\n",
        "  Fraud_arr = Input_Dataframe[Target]\n",
        "  # propability of Fraud and not Fraud\n",
        "  P_isF = float(len(Fraud_arr[Fraud_arr == Target_value])/length)\n",
        "\n",
        "  P_notF = 1-P_isF\n",
        "  if (P_isF == 1) or (P_notF == 1):\n",
        "    return 0\n",
        "  Chi_sq = 0 # target split_feature's Chi square value\n",
        "  alpha = 0.05 # your choose alpha value for the basic Chi-square values\n",
        "\n",
        "  if Split_feature in Categoric_features:    \n",
        "    Feature_classes = np.unique(Input_Dataframe[Split_feature])\n",
        "    Degree_Freedom = (len(Feature_classes) - 1) * (2-1) # 2: T/F in isFraud\n",
        "    for i in Feature_classes:\n",
        "      Sub_df = Input_Dataframe[Input_Dataframe[Split_feature] == i]\n",
        "      Sub_len = len(Sub_df)\n",
        "      Sub_P_isF = len(Sub_df[Sub_df[Target] == Target_value])/Sub_len\n",
        "      Sub_P_notF = 1-Sub_P_isF\n",
        "      Chi_sq = Chi_sq + Sub_len * ((Sub_P_isF - P_isF)**2/P_isF + (Sub_P_notF - P_notF)**2/P_notF)\n",
        "    Chi_basic = chi2.ppf(1 - alpha, Degree_Freedom) - 5\n",
        "    \n",
        "  elif Split_feature in Numeric_features:\n",
        "    Degree_Freedom = 1*1\n",
        "    tmp_Input_Dataframe = Input_Dataframe.copy()\n",
        "    Split_pts_Num = Split_pts_Num\n",
        "    # create a new field in dataframe \"Num_Cat\" to binary separate the feature.\n",
        "    # notice that \"Num_Cat\" is also inside Categorical feature, check cell 4\n",
        "    tmp_Input_Dataframe.loc[tmp_Input_Dataframe[Split_feature] <= Split_pts_Num,'Num_Cat'] = 0\n",
        "    tmp_Input_Dataframe.loc[tmp_Input_Dataframe[Split_feature] > Split_pts_Num,'Num_Cat'] = 1\n",
        "    Chi_sq = Chi_test(tmp_Input_Dataframe,'Num_Cat')\n",
        "    Chi_basic = chi2.ppf(1 - alpha, Degree_Freedom) - 5\n",
        "  \n",
        "  if Split_feature != 'Num_Cat':\n",
        "    if Chi_sq > Chi_basic:\n",
        "      return 1  # good result, expanding\n",
        "    else:\n",
        "      return 0  # bad result, not expanding\n",
        "  if Split_feature == 'Num_Cat':\n",
        "      return Chi_sq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# demo of Chi_test\n",
        "Chi_test(train[0:4000],'ProductCD')\n",
        "Chi_test(train[0:4000],'C1', 50)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Tree Node Structure<br></b>\n",
        "| Node's property | Type | Definition |\n",
        "| --- | --- | --- |\n",
        "| <font color = 'green'> Self_Column</font> | String | Feature name for <b>the Node</b> |\n",
        "| <font color = 'green'> Sub_branches </font>| list or float | <b>the Node</b>'s edges |\n",
        "| <font color = 'green'> Sub_childs </font>| String | <b>the Node</b>'s children nodes |\n",
        "| <font color = 'green'> Parent_Col</font>| String | <b>the Node</b>'s parent node's feature name |\n",
        "| <font color = 'green'> Target</font> | float | <b>the Node</b>'s target|\n",
        "\n",
        "<b>Noted:</b><br>\n",
        "&emsp;-- For Categorical Features, Sub_branches equals to <b> the Node</b>'s unique values.  \n",
        "&emsp;-- For Numerical Features, Sub_branches is a single float number (x0), which has the best Information Gain. <br>\n",
        "&emsp;&emsp; Although <b> the Node</b>'s Sub_branches's length = 1, it has 2 Sub_childs. And the binary separation is done by the x0.<br>\n",
        "&emsp;-- When a node has a child, it's Target is NaN.\n",
        "<br>\n",
        "| Node's Function | Usage demo | Definition | Output\n",
        "| --- | --- | --- | --- |\n",
        "| <font color = 'green'> is_leaf_node(self)</font> | Node.is_leaf_node() | Determine whther <b>the Node</b> is a leaf node. | 1 (leaf node) / 0 (not a leaf node)|\n",
        "| <font color = 'green'> set_values(self, column, branch) </font>| Node.set_values(column = 'ProductCD', branch = ['W','R']) | Setting the property of <b>the Node</b> | No output|\n",
        "| <font color = 'green'> set_Target(self, target) </font>| Node.set_Target(1) | Setting the property of <b>the Node</b> | No output|\n",
        "| <font color = 'green'> add_child(self, node):</font>| Node.add_child(node = child_node)| link <b>the Node</b> with its child node |  No output|\n",
        "| <font color = 'green'> set_parent(self, parent_col) | Node.set_parent('card1') | Setting the property of <b>the Node</b>  | No output|\n",
        "| <font color = 'green'> get_target(self)</font>| Node.get_target() | Getting the Target value | 1 (Farud) / 0 (Not Fraud) / Nan (not a leaf node)|\n",
        "| <font color = 'green'> get_column(self) </font>| Node.get_column() | Getting the property of <b>the Node</b> | <b>the Node</b>'s Feature name|\n",
        "| <font color = 'green'> get_branch(self):</font>| Node.get_branch()| Getting all property of <b>the Node</b>|  list [] if the node represent a Categorical Feature / float number if the node is a Numerical Feature|\n",
        "| <font color = 'green'> get_child(self):</font>| Node.get_child()| Getting all children nodes of <b>the Node</b>|  TreeNode() structure|\n",
        "\n",
        "_________________________\n",
        "________________________\n",
        "\n",
        "<br>\n",
        "\n",
        "<b>Build one Decision Tree<br></b>\n",
        "| Input Variable | Type | Definition |\n",
        "| --- | --- | --- |\n",
        "| <font color = 'green'> Input_Dataframe</font> | pandas.DataFrame | The DataFrame of the Training data |\n",
        "| <font color = 'green'> total_Col </font>| List | A list of usable features, defalut to be all features |\n",
        "| <font color = 'green'> IG_methods</font> | String | Information Gain Method, 'Gini'/ 'Entropy' / 'MisEr', defalut to be 'Gini'|\n",
        "| <font color = 'green'> depth</font> | float | The current depth's of the tree, default to be 0, only to be used inside the function for a recurssion purpose|\n",
        "\n",
        "<br>\n",
        "This function will return a root node of a tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, Self_Column = None, Sub_branches = None, Target = None, Sub_childs = None, Parent_Col = None):\n",
        "        self.Self_Column = Self_Column \n",
        "        self.Sub_branches = Sub_branches if Sub_branches is not None else []\n",
        "        self.Target = Target\n",
        "        self.Sub_childs = Sub_childs if Sub_childs is not None else []\n",
        "        self.Parent_Col = Parent_Col\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.Target is not None\n",
        "    \n",
        "    def set_values(self, column, branch):\n",
        "        self.Self_Column = column\n",
        "        self.Sub_branches = branch\n",
        "    \n",
        "    def set_Target(self, target):\n",
        "        self.Target = target\n",
        "    \n",
        "    def add_child(self, node):\n",
        "        self.Sub_childs.append(node)\n",
        "        node.set_parent(self.Self_Column)\n",
        "\n",
        "    def get_branch(self):\n",
        "        return self.Sub_branches\n",
        "    \n",
        "    def get_child(self):\n",
        "        return self.Sub_childs\n",
        "    \n",
        "    def get_column(self):\n",
        "        return self.Self_Column\n",
        "    \n",
        "    def get_target(self):\n",
        "        return self.Target\n",
        "    \n",
        "    def set_parent(self, parent_col):\n",
        "        self.Parent_Col = parent_col\n",
        "        \n",
        "\n",
        "    \n",
        "    \n",
        "def build_DT(Input_Dataframe, total_Col = Columns, IG_methods = 'Gini', depth = 0):\n",
        "    #IG_methods = 'Gini'/ 'Entropy' / 'MisEr'\n",
        "    IG_method = IG_methods\n",
        "\n",
        "\n",
        "    ############ can change the maximum depth of the tree here ###############\n",
        "    max_depth = 5\n",
        "    ############ can change the maximum depth of the tree here ###############\n",
        "\n",
        "\n",
        "    Root_node = TreeNode()\n",
        "    self_col = Input_Dataframe.columns.values\n",
        "    depth = depth\n",
        "    \n",
        "    ################# find the best Information Gain feature ###################\n",
        "    ################# and return the best split point if it is a numerical feature ###############\n",
        "    IG_columns = pd.DataFrame(columns= ['Column', 'IG', 'SplitPts'])\n",
        "    n = 0\n",
        "    for i in self_col:\n",
        "        #print (i)\n",
        "        if i == Target or i == Index or not (i in total_Col):\n",
        "            continue\n",
        "        elif i in Categoric_features:\n",
        "            [tmp_IG, Split_pts] = Info_Gain(Input_Dataframe, i, IG_method, 'Cat')\n",
        "        elif i in Numeric_features:\n",
        "            [tmp_IG, Split_pts] = Info_Gain(Input_Dataframe, i, IG_method, 'Num')\n",
        "        #print (i, total_Col, 'i in total_Col', i in total_Col)\n",
        "        IG_columns.loc[n,'Column'] = i\n",
        "        IG_columns.loc[n,'IG'] = tmp_IG\n",
        "        IG_columns.loc[n,'SplitPts'] = Split_pts\n",
        "        n = n + 1\n",
        "    ################# and return the best split point if it is a numerical feature ###############\n",
        "    ################# find the best Information Gain feature ###################\n",
        "    \n",
        "\n",
        "\n",
        "    ############################ create a node for this selected feature ########################\n",
        "    #print (IG_columns)\n",
        "    Best_IG = IG_columns['IG'].max()\n",
        "    [Best_Column, Split_Pts] = IG_columns.loc[IG_columns['IG'] == Best_IG, ['Column', 'SplitPts']].values[0]\n",
        "    #print (Best_Column,Split_Pts)\n",
        "    \n",
        "    if Best_Column in Categoric_features:\n",
        "        Root_node.set_values(Best_Column, np.unique(Input_Dataframe[Best_Column]))    \n",
        "    elif Best_Column in Numeric_features:\n",
        "        Root_node.set_values(Best_Column, Split_Pts)\n",
        "    ############################ create a node for this selected feature ########################\n",
        "\n",
        "\n",
        "\n",
        "    ############################ If the node failed the Chi-test, stop the tree ########################\n",
        "    if (not Chi_test(Input_Dataframe, Best_Column, Split_Pts)):\n",
        "        Root_node.set_Target(Input_Dataframe[Target].mode()[0])\n",
        "        #print ('fail chi_test:', depth, Best_Column)\n",
        "        #print ('max_depth', max_depth, depth == max_depth)\n",
        "        return Root_node\n",
        "    ############################ If the node failed the Chi-test, stop the tree ########################\n",
        "\n",
        "\n",
        "\n",
        "    ############################ If the node failed the Chi-test, recursively expand the tree ########################\n",
        "    else:\n",
        "        depth = depth + 1\n",
        "\n",
        "        #print ('pass chi_test:', depth)\n",
        "        if depth < max_depth:\n",
        "            #print ('in, Self_Col:', Root_node.get_column())\n",
        "            #print ('in, Self_branch:', Root_node.get_branch())\n",
        "            #print ('in, Self_branch_len:', len(Root_node.get_branch()))\n",
        "            if (Root_node.Self_Column in Categoric_features) and (Root_node.Self_Column in total_Col):                \n",
        "                for i in Root_node.Sub_branches:\n",
        "                    #print ('Current Sub_Branch = ',i)\n",
        "                    Sub_DF = Input_Dataframe[Input_Dataframe[Root_node.Self_Column] == i]    \n",
        "                    tmp_Col = total_Col[total_Col != i]               \n",
        "                    Root_node.add_child(build_DT(Sub_DF, tmp_Col, IG_method, depth))\n",
        "                \n",
        "                #print (\"cat:\", depth)\n",
        "            elif (Root_node.Self_Column in Numeric_features) and (Root_node.Self_Column in total_Col):\n",
        "                \n",
        "                Sub_DF_left = Input_Dataframe[Input_Dataframe[Root_node.Self_Column] <= Root_node.Sub_branches]\n",
        "                tmp_Col = total_Col[total_Col != i]\n",
        "                Root_node.add_child(build_DT(Sub_DF_left, tmp_Col, IG_method, depth))\n",
        "                Sub_DF_right = Input_Dataframe[Input_Dataframe[Root_node.Self_Column] > Root_node.Sub_branches]\n",
        "                tmp_Col = total_Col[total_Col != i]\n",
        "                Root_node.add_child(build_DT(Sub_DF_right, tmp_Col, IG_method, depth))\n",
        "                \n",
        "                \n",
        "                #print (\"num:\", depth)\n",
        "        else:\n",
        "            #print (\"depth maximum\")\n",
        "            Root_node.set_Target(Input_Dataframe[Target].mode()[0])\n",
        "        return Root_node\n",
        "    ############################ If the node failed the Chi-test, recursively expand the tree ########################\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>DT_Predict :</b> Travelse the tree for prediction<br>\n",
        "| Input Variable | Type | Definition |\n",
        "| --- | --- | --- |\n",
        "| <font color = 'green'> Input_Dataframe</font> | pandas.DataFrame | <b> One </b> record from the DataFrame of the testing/validation data |\n",
        "| <font color = 'green'> Tree_node </font>| TreeNode() | The root node of one tree. |\n",
        "\n",
        "<br>\n",
        "This function will return a whether the targeted record is \"Fraud\" or \"NotFraud\".<br>\n",
        "\n",
        "<b>Noted:</b><br>\n",
        "In some cases, the trained tree has not seen a feature value from the testing/validation data, or the testing/validation data has a missing value. <br>\n",
        "This function will return a list of all potential target values for the situations. <br>\n",
        "Please refer to the <b>Section 1.2 in the report </b> for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def DT_Predict(Input_Dataframe,Tree_node):\n",
        "    tmp_node = Tree_node\n",
        "    potential_predict = np.array([])\n",
        "    list_TF = 0\n",
        "\n",
        "    ################### DFS #######################\n",
        "    while not tmp_node.is_leaf_node():\n",
        "        tmp_col = tmp_node.get_column()\n",
        "        #print (tmp_col)\n",
        "        #tmp_col = tmp_node.Self_Column\n",
        "        #print (Input_Dataframe[tmp_col])\n",
        "        data_val = Input_Dataframe[tmp_col].values[0]\n",
        "        branches = tmp_node.get_branch()\n",
        "        #branches = tmp_node.Sub_branches\n",
        "        \n",
        "        if tmp_col in Categoric_features:\n",
        "            #print (\"cat:\", tmp_col)\n",
        "            #print (data_val)\n",
        "            sub_node_idx = np.where(branches == data_val)[0]\n",
        "            if sub_node_idx.shape[0] > 0:\n",
        "                sub_node_idx = sub_node_idx[0]\n",
        "                list_TF = 0\n",
        "            else:\n",
        "                sub_node_idx = -1\n",
        "                list_TF = 1\n",
        "                \n",
        "        elif tmp_col in Numeric_features:\n",
        "            list_TF = 0\n",
        "            #print (\"num:\", tmp_col)\n",
        "            if data_val <= branches:\n",
        "                sub_node_idx = 0\n",
        "            else:\n",
        "                sub_node_idx = 1\n",
        "        \n",
        "        child_nodes = tmp_node.get_child()\n",
        "        #print (sub_node_idx)\n",
        "        #print (child_nodes)\n",
        "\n",
        "        ########################### when the tree has not seen the value or it is a missing data ##########################\n",
        "        if sub_node_idx == -1:\n",
        "            for i in branches:\n",
        "                tmp_Dataframe = Input_Dataframe.copy()\n",
        "                sub_node_idx = np.where(branches == i)[0][0]\n",
        "                tmp_node = child_nodes[sub_node_idx]\n",
        "                tmp_Dataframe[tmp_col] = i\n",
        "                potential_predict = np.append(potential_predict, DT_Predict(tmp_Dataframe, tmp_node))\n",
        "        ########################### when the tree has not seen the value or it is a missing data ##########################\n",
        "        \n",
        "        else:\n",
        "            #print (sub_node_idx)\n",
        "            #print (tmp_node.get_column(), len(tmp_node.get_child()), tmp_node.is_leaf_node(), tmp_node.get_target())\n",
        "            tmp_node = child_nodes[sub_node_idx]\n",
        "    #print (sub_node_idx)\n",
        "    ################### DFS #######################\n",
        "\n",
        "\n",
        "    if list_TF == 1:\n",
        "        return potential_predict\n",
        "    else:\n",
        "        return tmp_node.Target\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>tree_df :</b> Saving the tree to a DataFrame<br>\n",
        "| Input Variable | Type | Definition |\n",
        "| --- | --- | --- |\n",
        "| <font color = 'green'> root_node </font>| TreeNode() | The root node of one tree. |\n",
        "\n",
        "<br>\n",
        "This function will return a DataFrame to store the tree.<br>\n",
        "More details are included in the report.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<b>Predict_df :</b> Using the dataframe to do a prediction<br>\n",
        "\n",
        "| Input Variable | Type | Definition |\n",
        "| --- | --- | --- |\n",
        "| <font color = 'green'> Input_Dataframe</font> | pandas.DataFrame | <b> One </b> record from the DataFrame of the testing/validation data |\n",
        "| <font color = 'green'> tree_df </font>| pandas.DataFrame | The DataFrame represening the tree |\n",
        "| <font color = 'green'> current_index </font>| int | The index from the DataFrame, only used for recursive purpose inside the function itself |\n",
        "\n",
        "<br>\n",
        "The basic logic of this function is the same as <b>DT_Predict </b>. <br>\n",
        "The only difference is that this function is using <b> current_index </b> to track done the current node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tree_df(root_node):\n",
        "\n",
        "    queue = [(root_node,0,0)]\n",
        "    list_node = []\n",
        "    while queue:\n",
        "        current_node, depth, sub_branch = queue.pop(0)\n",
        "        current_col_name = current_node.get_column()\n",
        "        current_branches = current_node.get_branch()\n",
        "        current_childs = current_node.get_child()\n",
        "        childs_name = []\n",
        "        for i in range(len(current_childs)):\n",
        "            childs_name.append(current_childs[i].get_column())\n",
        "        list_node.append((current_col_name,current_branches,childs_name,depth, current_node.get_target(),current_node.Parent_Col,sub_branch))\n",
        "        #print (list_node)\n",
        "        tmp_child = current_node.get_child()\n",
        "        if len(tmp_child) > 0:\n",
        "            if current_col_name in Categoric_features:\n",
        "                for i in range(len(tmp_child)):\n",
        "                    queue.append((tmp_child[i],depth+1,current_branches[i]))\n",
        "            elif current_col_name in Numeric_features:\n",
        "                queue.append((tmp_child[0],depth+1,current_branches))\n",
        "                queue.append((tmp_child[1],depth+1,current_branches+1))\n",
        "\n",
        "    tree_df = pd.DataFrame(list_node,columns = ['Column_name','Branches','Child_Columns','Depth','Target','Parent_Col','Parent_Branch'])\n",
        "    return tree_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Predict_df(Input_Dataframe,tree_df, current_index = 0):\n",
        "\n",
        "    potential_predict = np.array([])\n",
        "    list_TF = 0\n",
        "    current_index = current_index\n",
        "    while pd.isna(tree_df.loc[current_index,'Target']):\n",
        "        \n",
        "        tmp_col = tree_df.loc[current_index,'Column_name']\n",
        "        data_val = Input_Dataframe[tmp_col].values[0]\n",
        "        branches = tree_df.loc[current_index,'Branches']\n",
        "        current_depth = tree_df.loc[current_index,'Depth']\n",
        "        if tmp_col in Categoric_features:\n",
        "            #print (\"cat:\", tmp_col)\n",
        "            #print (data_val)\n",
        "            sub_node_idx = np.where(branches == data_val)[0]\n",
        "            if sub_node_idx.shape[0] > 0:\n",
        "                sub_node_idx = sub_node_idx[0]\n",
        "                tmp_branch = branches[sub_node_idx]\n",
        "                list_TF = 0\n",
        "            else:\n",
        "                sub_node_idx = -1\n",
        "                list_TF = 1\n",
        "                \n",
        "        elif tmp_col in Numeric_features:\n",
        "            list_TF = 0\n",
        "            #print (\"num:\", tmp_col)\n",
        "            if data_val <= branches:\n",
        "                sub_node_idx = 0\n",
        "                tmp_branch = branches\n",
        "            else:\n",
        "                sub_node_idx = 1\n",
        "                tmp_branch = branches + 1\n",
        "        \n",
        "        child_nodes_name = tree_df.loc[current_index,'Child_Columns']\n",
        "\n",
        "        if sub_node_idx == -1:\n",
        "            for i in branches:\n",
        "                tmp_Dataframe = Input_Dataframe.copy()\n",
        "                #print ('i=', i)\n",
        "                #print (branches,np.where(branches == i)[0])\n",
        "                branch_idx = np.where(branches == i)[0][0]\n",
        "                \n",
        "                Child_Name = child_nodes_name[branch_idx]\n",
        "                \n",
        "                current_index = tree_df[(tree_df['Column_name'] == Child_Name) & (tree_df['Parent_Col'] == tmp_col) & (tree_df['Parent_Branch'] == i) & (tree_df['Depth'] == current_depth + 1)].index[0]\n",
        "                \n",
        "                tmp_Dataframe[tmp_col] = i\n",
        "                potential_predict = np.append(potential_predict, Predict_df(tmp_Dataframe, tree_df, current_index))\n",
        "        else:\n",
        "            #print (tmp_node.get_column(), len(tmp_node.get_child()), tmp_node.is_leaf_node(), tmp_node.get_target())\n",
        "\n",
        "            current_index = tree_df[(tree_df['Column_name'] == child_nodes_name[sub_node_idx]) & (tree_df['Parent_Col'] == tmp_col) & (tree_df['Parent_Branch'] == tmp_branch) & (tree_df['Depth'] == current_depth + 1)].index[0]\n",
        "    #print (sub_node_idx)\n",
        "    if list_TF == 1:\n",
        "        return potential_predict\n",
        "    else:\n",
        "        return tree_df.loc[current_index,'Target']\n",
        "\n",
        "#tree_df(tree_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Build Random Forest </b><br>\n",
        "Using <b>DT_Predict</b> function <br>\n",
        "In line 57, some other version may require you remove the index, the optional line is added in line 58"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3261, 27)\n",
            "0th DT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/823 [00:00<?, ?it/s]C:\\Users\\cgirlamo\\AppData\\Local\\Temp\\ipykernel_3144\\1479823888.py:57: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  predict.append(mode(target_predict).mode[0])\n",
            "100%|██████████| 823/823 [00:01<00:00, 575.14it/s]\n",
            "100%|██████████| 823/823 [00:00<00:00, 9073.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Balanced_Acc: 0.49937733499377335\n",
            "(3261, 27)\n",
            "1th DT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/823 [00:00<?, ?it/s]C:\\Users\\cgirlamo\\AppData\\Local\\Temp\\ipykernel_3144\\1479823888.py:57: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  predict.append(mode(target_predict).mode[0])\n",
            "100%|██████████| 823/823 [00:01<00:00, 500.35it/s]\n",
            "100%|██████████| 823/823 [00:00<00:00, 9371.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Balanced_Acc: 0.4987546699875467\n",
            "(3261, 27)\n",
            "2th DT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 823/823 [00:00<00:00, 1793.74it/s]\n",
            "100%|██████████| 823/823 [00:00<00:00, 9706.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Balanced_Acc: 0.49937733499377335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# How many trees inside the random forest \n",
        "Tree_no = 3\n",
        "\n",
        "All_predict = []\n",
        "All_observe = []\n",
        "\n",
        "\n",
        "for ii in range(Tree_no):\n",
        "    # shuffle the train.csv dataset so that each tree is using different subset\n",
        "    # this is using train_filter, you can also use train_Impu\n",
        "    train_filter = train_filter.sample(frac = 1)\n",
        "    # split the train.csv dataset into \"positive\" and \"negative\" based on \"Fraud\" or \"not Fruad\"\n",
        "    positive = train_filter[train_filter['isFraud'] == 1]\n",
        "    negative = train_filter[train_filter['isFraud'] == 0]\n",
        "    pos_size = positive.shape\n",
        "    neg_size = negative.shape\n",
        "\n",
        "    \n",
        "    # 0.002: 0.2% of positive and negative into test \n",
        "    test_positive = positive[0:int(pos_size[0]*0.002)] \n",
        "    test_negative = negative[0:int(neg_size[0]*0.002)]\n",
        "\n",
        "    # [0.002: 1/100]: 0.8% of positive and negative into training\n",
        "    train_positive = positive[int(pos_size[0]*0.002):int(pos_size[0]/100)]\n",
        "    train_negative = negative[int(neg_size[0]*0.002):int(neg_size[0]/100)]\n",
        "\n",
        "    # create the pool for training and validation\n",
        "    pool_train = pd.concat([train_positive, train_negative])\n",
        "    pool_test = pd.concat([test_positive, test_negative])\n",
        "    pool_test = pool_test.sample(frac = 1)\n",
        "    exp_test = pool_test[0:int(len(pool_test))]\n",
        "\n",
        "    # randomly select 20 features for each tree\n",
        "    np.random.shuffle(Columns)\n",
        "    tmp_total_Col = Columns[0:20] # change 20 to select more or less columns\n",
        "\n",
        "    pool_train = pool_train.sample(frac = 1)\n",
        "    exp_train = pool_train[0:int(len(pool_train)*0.99)]\n",
        "    print (exp_train.shape)\n",
        "\n",
        "    observe = []\n",
        "    predict = [] \n",
        "    #IG_methods = 'Gini'/ 'Entropy' / 'MisEr'\n",
        "    tree_node = build_DT(exp_train, total_Col= tmp_total_Col, IG_methods = 'Gini')\n",
        "    T_Df = tree_df(tree_node)\n",
        "    T_Df.to_pickle('Tree_Gini_Filt' + str(ii) + '.pkl')\n",
        "    \n",
        "    print (str(ii) + 'th DT')\n",
        "    for i in tqdm(range(exp_test.shape[0])):\n",
        "        tmp_dataframe = pd.DataFrame(exp_test.iloc[i]).T\n",
        "        #(type(tmp_dataframe))\n",
        "        #print (tmp_dataframe)\n",
        "        target_predict = DT_Predict(tmp_dataframe,tree_node)\n",
        "        if not isinstance(target_predict, np.ndarray):\n",
        "            predict.append(target_predict)\n",
        "        else:\n",
        "            predict.append(mode(target_predict).mode[0])\n",
        "            #predict.append(mode(target_predict).mode)\n",
        "    observe = exp_test[Target]\n",
        "\n",
        "\n",
        "    ################### Calculate the Confuse Matrix and Balanced Acc #####################\n",
        "    All_predict.append(predict)\n",
        "    All_observe.append(observe)\n",
        "\n",
        "    Confuse_Matrix = pd.DataFrame(0,columns = ['Predict_T','Predict_F'],index= ['Observe_T','Observe_F'])\n",
        "    for i in tqdm(range(len(predict))):\n",
        "        if predict[i] == 1 and observe.iloc[i] == 1:\n",
        "            Confuse_Matrix.loc['Observe_T','Predict_T'] = Confuse_Matrix.loc['Observe_T','Predict_T'] + 1\n",
        "        elif predict[i] == 1 and observe.iloc[i] == 0:\n",
        "            Confuse_Matrix.loc['Observe_F','Predict_T'] = Confuse_Matrix.loc['Observe_F','Predict_T'] + 1\n",
        "        elif predict[i] == 0 and observe.iloc[i] == 1:\n",
        "            Confuse_Matrix.loc['Observe_T','Predict_F'] = Confuse_Matrix.loc['Observe_T','Predict_F'] + 1\n",
        "        elif predict[i] == 0 and observe.iloc[i] == 0:\n",
        "            Confuse_Matrix.loc['Observe_F','Predict_F'] = Confuse_Matrix.loc['Observe_F','Predict_F'] + 1\n",
        "    Recall_P = Confuse_Matrix.loc['Observe_T','Predict_T'] / sum(Confuse_Matrix.loc['Observe_T'])\n",
        "    Recall_F = Confuse_Matrix.loc['Observe_F','Predict_F'] / sum(Confuse_Matrix.loc['Observe_F'])\n",
        "    Balanced_Acc = (Recall_P + Recall_F)/2\n",
        "    print(\"Balanced_Acc:\", Balanced_Acc)\n",
        "    Confuse_Matrix.to_csv('Conf_Mat_Gini_Filt' + str(ii))\n",
        "    ################### Calculate the Confuse Matrix and Balanced Acc #####################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'All_predict' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\PhD\\2year\\529\\Assignment\\HM1_DT_CS529\\HM1 copy.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/PhD/2year/529/Assignment/HM1_DT_CS529/HM1%20copy.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m All_predict\n",
            "\u001b[1;31mNameError\u001b[0m: name 'All_predict' is not defined"
          ]
        }
      ],
      "source": [
        "All_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column_name</th>\n",
              "      <th>Branches</th>\n",
              "      <th>Child_Columns</th>\n",
              "      <th>Depth</th>\n",
              "      <th>Target</th>\n",
              "      <th>Parent_Col</th>\n",
              "      <th>Parent_Branch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>card3</td>\n",
              "      <td>[106.0, 117.0, 143.0, 144.0, 146.0, 147.0, 150...</td>\n",
              "      <td>[ProductCD, ProductCD, ProductCD, ProductCD, P...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ProductCD</td>\n",
              "      <td>[C]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>card3</td>\n",
              "      <td>106.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ProductCD</td>\n",
              "      <td>[R]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>card3</td>\n",
              "      <td>117.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ProductCD</td>\n",
              "      <td>[W]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>card3</td>\n",
              "      <td>143.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ProductCD</td>\n",
              "      <td>[H]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>card3</td>\n",
              "      <td>144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ProductCD</td>\n",
              "      <td>[W]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>card3</td>\n",
              "      <td>146.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ProductCD</td>\n",
              "      <td>[C]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>card3</td>\n",
              "      <td>147.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>C13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[card2, C10]</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>card3</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ProductCD</td>\n",
              "      <td>[H]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>card3</td>\n",
              "      <td>181.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ProductCD</td>\n",
              "      <td>[C]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>card3</td>\n",
              "      <td>185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ProductCD</td>\n",
              "      <td>[H]</td>\n",
              "      <td>[]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>card3</td>\n",
              "      <td>191.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>card2</td>\n",
              "      <td>[100.0, 105.0, 110.0, 111.0, 122.0, 155.0, 170...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>C13</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>C10</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[card2, card2]</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C13</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>card2</td>\n",
              "      <td>[100.0, 101.0, 102.0, 105.0, 106.0, 108.0, 110...</td>\n",
              "      <td>[]</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>C10</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>card2</td>\n",
              "      <td>[111.0, 161.0, 174.0, 250.0, 327.0, 360.0, 383...</td>\n",
              "      <td>[]</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>C10</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Column_name                                           Branches  \\\n",
              "0        card3  [106.0, 117.0, 143.0, 144.0, 146.0, 147.0, 150...   \n",
              "1    ProductCD                                                [C]   \n",
              "2    ProductCD                                                [R]   \n",
              "3    ProductCD                                                [W]   \n",
              "4    ProductCD                                                [H]   \n",
              "5    ProductCD                                                [W]   \n",
              "6    ProductCD                                                [C]   \n",
              "7          C13                                                0.0   \n",
              "8    ProductCD                                                [H]   \n",
              "9    ProductCD                                                [C]   \n",
              "10   ProductCD                                                [H]   \n",
              "11       card2  [100.0, 105.0, 110.0, 111.0, 122.0, 155.0, 170...   \n",
              "12         C10                                                2.0   \n",
              "13       card2  [100.0, 101.0, 102.0, 105.0, 106.0, 108.0, 110...   \n",
              "14       card2  [111.0, 161.0, 174.0, 250.0, 327.0, 360.0, 383...   \n",
              "\n",
              "                                        Child_Columns  Depth  Target  \\\n",
              "0   [ProductCD, ProductCD, ProductCD, ProductCD, P...      0     NaN   \n",
              "1                                                  []      1     0.0   \n",
              "2                                                  []      1     0.0   \n",
              "3                                                  []      1     0.0   \n",
              "4                                                  []      1     1.0   \n",
              "5                                                  []      1     0.0   \n",
              "6                                                  []      1     0.0   \n",
              "7                                        [card2, C10]      1     NaN   \n",
              "8                                                  []      1     1.0   \n",
              "9                                                  []      1     0.0   \n",
              "10                                                 []      1     0.0   \n",
              "11                                                 []      2     0.0   \n",
              "12                                     [card2, card2]      2     NaN   \n",
              "13                                                 []      3     0.0   \n",
              "14                                                 []      3     0.0   \n",
              "\n",
              "   Parent_Col Parent_Branch  \n",
              "0        None             0  \n",
              "1       card3         106.0  \n",
              "2       card3         117.0  \n",
              "3       card3         143.0  \n",
              "4       card3         144.0  \n",
              "5       card3         146.0  \n",
              "6       card3         147.0  \n",
              "7       card3         150.0  \n",
              "8       card3         181.0  \n",
              "9       card3         185.0  \n",
              "10      card3         191.0  \n",
              "11        C13           0.0  \n",
              "12        C13           1.0  \n",
              "13        C10           2.0  \n",
              "14        C10           3.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "T_Df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Predict_np :</b> Using a numpy.Array to do a prediction<br>\n",
        "\n",
        "| Input Variable | Type | Definition |\n",
        "| --- | --- | --- |\n",
        "| <font color = 'green'> Input_np</font> | pandas.DataFrame | <b> One </b> record from the Array of the testing/validation data |\n",
        "| <font color = 'green'> tree_np </font>| pandas.DataFrame | The Array represening the tree |\n",
        "| <font color = 'green'> current_index </font>| int | The index from the DataFrame, only used for recursive purpose inside the function itself |\n",
        "\n",
        "<br>\n",
        "The basic logic of this function is the same as <b>Predict_df </b>. <br>\n",
        "The only difference is that this function is using column index instead of column (feature name) itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "Columns = train.columns.values\n",
        "Columns = Columns[Columns != Index]\n",
        "Columns = Columns[Columns != Date]\n",
        "Categoric_features_index = np.where(np.isin(Columns,Categoric_features))[0]\n",
        "Numeric_features_index = np.where(np.isin(Columns,Numeric_features))[0]\n",
        "\n",
        "\n",
        "def Predict_np(Input_np, tree_np, current_index = 0):\n",
        "                       \n",
        "    potential_predict = np.array([])\n",
        "    list_TF = 0\n",
        "    #current_index = current_index\n",
        "    while np.isnan(tree_np[current_index][4]): #[4]:\"Target\"\n",
        "        \n",
        "        tmp_col = tree_np[current_index][0] # [0]: 'Column_name'\n",
        "        #print (tmp_col)\n",
        "        tmp_col_index = np.where(Columns == tmp_col)[0][0] \n",
        "        #print (tmp_col_index)\n",
        "        data_val = Input_np[tmp_col_index]\n",
        "        branches = tree_np[current_index][1] # [1]:'Branches'\n",
        "        current_depth = tree_np[current_index][3]\n",
        "        if tmp_col_index in Categoric_features_index:\n",
        "            #print (\"cat:\", tmp_col)\n",
        "            #print (data_val)\n",
        "            sub_node_idx = np.where(branches == data_val)[0]\n",
        "            if sub_node_idx.shape[0] > 0:\n",
        "                sub_node_idx = sub_node_idx[0]\n",
        "                tmp_branch = branches[sub_node_idx]\n",
        "                list_TF = 0\n",
        "            else:\n",
        "                sub_node_idx = -1\n",
        "                list_TF = 1\n",
        "                \n",
        "        elif tmp_col_index in Numeric_features_index:\n",
        "            list_TF = 0\n",
        "            #print (\"num:\", tmp_col)\n",
        "            if data_val <= branches:\n",
        "                sub_node_idx = 0\n",
        "                tmp_branch = branches\n",
        "            else:\n",
        "                sub_node_idx = 1\n",
        "                tmp_branch = branches + 1\n",
        "        \n",
        "        child_nodes_name = tree_np[current_index][2] #[2]: \"Child_Columns\"\n",
        "        \n",
        "        if sub_node_idx == -1:\n",
        "            len_branches = len(branches)\n",
        "            branch_index_pool = np.arange(len_branches)\n",
        "            np.random.shuffle(branch_index_pool)\n",
        "            n = 0\n",
        "            #tmp_np = np.array()\n",
        "            #print (tmp_col, len(branches))\n",
        "            for i in branch_index_pool:\n",
        "                tmp_np = Input_np.copy()\n",
        "                #print ('i=', i)\n",
        "                #print (branches,np.where(branches == i)[0])\n",
        "                branch_idx = i\n",
        "                n = n + 1\n",
        "                if len_branches > 1000 & n > len_branches/20:\n",
        "                    break\n",
        "                Child_Name = child_nodes_name[branch_idx]\n",
        "                current_index = np.where((tree_np[:,0] == Child_Name) & (tree_np[:,5] ==tmp_col) & (tree_np[:,6] == branches[branch_idx]) & (tree_np[:, 3] == current_depth + 1))[0][0]\n",
        "                #current_index = tree_df[(tree_df['Column_name'] == Child_Name) & (tree_df['Parent_Col'] == tmp_col) & (tree_df['Parent_Branch'] == i)].index[0]\n",
        "                \n",
        "                tmp_np[tmp_col_index] = i\n",
        "                potential_predict = np.append(potential_predict, Predict_np(tmp_np, tree_np, current_index))\n",
        "        else:\n",
        "            #print (tmp_node.get_column(), len(tmp_node.get_child()), tmp_node.is_leaf_node(), tmp_node.get_target())\n",
        "            current_index = np.where((tree_np[:,0] == child_nodes_name[sub_node_idx]) & (tree_np[:,5] ==tmp_col) & (tree_np[:,6] == tmp_branch) & (tree_np[:, 3] == current_depth + 1))[0][0]\n",
        "            \n",
        "    #print (sub_node_idx)\n",
        "    if list_TF == 1:\n",
        "        return potential_predict\n",
        "    else:\n",
        "        return tree_np[current_index][4]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Demo of using <b>Predict_df</b> and <b>Predict_np</b><br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "obser: [0]\n",
            "[Tree, DF, NP]: [ 0 , 0.0 , 0.0 ]\n"
          ]
        }
      ],
      "source": [
        "observe = -1\n",
        "predict_tree = -1\n",
        "predict_df = -1\n",
        "predict_np = -1\n",
        "#IG_methods = 'Gini'/ 'Entropy' / 'MisEr'\n",
        "\n",
        "i = 50 # change it to your desired record index\n",
        "tmp_dataframe = pd.DataFrame(exp_test.iloc[i]).T\n",
        "observe = tmp_dataframe[Target].values\n",
        "\n",
        "######## using DT_Predict (trees) ############\n",
        "target_predict = DT_Predict(tmp_dataframe,tree_node)\n",
        "if not isinstance(target_predict, np.ndarray):\n",
        "    predict_tree = target_predict\n",
        "else:\n",
        "    predict_tree = mode(target_predict).mode[0] # may have error for different mode version. Can switch to line 14\n",
        "    #predict_tree = mode(target_predict).mode\n",
        "######## using DT_Predict (trees) ############\n",
        "\n",
        "\n",
        "\n",
        "######## using Predict_df (DF) ############\n",
        "target_predict = Predict_df(tmp_dataframe,T_Df)\n",
        "if not isinstance(target_predict, np.ndarray):\n",
        "    predict_df = target_predict\n",
        "else:\n",
        "    predict_df = mode(target_predict).mode[0]\n",
        "    #predict_df = mode(target_predict).mode\n",
        "######## using Predict_df (DF) ############\n",
        "\n",
        "\n",
        "\n",
        "######## using Predict_np (np.Array) ############\n",
        "T_np = np.array(T_Df)\n",
        "tmp_dataframe_copy = tmp_dataframe.copy()\n",
        "tmp_dataframe_copy = tmp_dataframe_copy.drop(columns = [Index,Date])\n",
        "tmp_np = np.array(tmp_dataframe_copy)[0]\n",
        "\n",
        "target_predict = Predict_np(tmp_np,T_np)\n",
        "if not isinstance(target_predict, np.ndarray):\n",
        "    predict_np = target_predict\n",
        "else:\n",
        "    predict_np = mode(target_predict).mode[0]\n",
        "    #predict_np = mode(target_predict).mode\n",
        "######## using Predict_np (np.Array) ############\n",
        "\n",
        "\n",
        "print ('obser:', observe)\n",
        "print ('[Tree, DF, NP]: [', predict_tree, ',', predict_df,',', predict_np, ']')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
